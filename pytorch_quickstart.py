"""
PyTorch å¿«é€Ÿå…¥é—¨ç¤ºä¾‹
é€šè¿‡ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­å­¦ä¹  PyTorch çš„æ ¸å¿ƒæ¦‚å¿µï¼š
1. å¼ é‡ (Tensors)
2. æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
3. ç¥ç»ç½‘ç»œæ¨¡å‹
4. æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
5. è®­ç»ƒå’Œè¯„ä¼°
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import matplotlib.pyplot as plt

# æ£€æŸ¥æ˜¯å¦æœ‰GPUå¯ç”¨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# ============================
# 1. å¼ é‡åŸºç¡€æ“ä½œ
# ============================
print("\n" + "="*50)
print("1. PyTorch å¼ é‡åŸºç¡€")
print("="*50)

# åˆ›å»ºå¼ é‡
x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)
print(f"ä¸€ç»´å¼ é‡: {x}")

# åˆ›å»ºçŸ©é˜µ
matrix = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)
print(f"äºŒç»´å¼ é‡: \n{matrix}")

# éšæœºå¼ é‡
random_tensor = torch.randn(3, 4)  # 3x4çš„éšæœºå¼ é‡
print(f"éšæœºå¼ é‡: \n{random_tensor}")

# å¼ é‡è¿ç®—
a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])
print(f"å¼ é‡åŠ æ³•: {a + b}")
print(f"å¼ é‡ä¹˜æ³•: {a * b}")
print(f"çŸ©é˜µä¹˜æ³•: {torch.mm(matrix, matrix.T)}")

# ============================
# 2. ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†
# ============================
print("\n" + "="*50)
print("2. åˆ›å»ºæ•°æ®é›† - äºŒå…ƒåˆ†ç±»é—®é¢˜")
print("="*50)

def generate_data(n_samples=1000):
    """ç”Ÿæˆä¸€ä¸ªç®€å•çš„äºŒå…ƒåˆ†ç±»æ•°æ®é›†"""
    np.random.seed(42)
    
    # ç”Ÿæˆä¸¤ä¸ªé«˜æ–¯åˆ†å¸ƒçš„æ•°æ®ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰
    class_0 = np.random.multivariate_normal([2, 2], [[1, 0.5], [0.5, 1]], n_samples//2)
    class_1 = np.random.multivariate_normal([6, 6], [[1, -0.5], [-0.5, 1]], n_samples//2)

    
    X = np.vstack([class_0, class_1])
    y = np.hstack([np.zeros(n_samples//2), np.ones(n_samples//2)])
    
    return X, y

# ç”Ÿæˆæ•°æ®
X_train, y_train = generate_data(800)
X_test, y_test = generate_data(200)

# è½¬æ¢ä¸ºPyTorchå¼ é‡
X_train_tensor = torch.FloatTensor(X_train)
y_train_tensor = torch.LongTensor(y_train)
X_test_tensor = torch.FloatTensor(X_test)
y_test_tensor = torch.LongTensor(y_test)

print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train_tensor.shape}")
print(f"è®­ç»ƒæ ‡ç­¾å½¢çŠ¶: {y_train_tensor.shape}")
print(f"ç‰¹å¾èŒƒå›´: [{X_train_tensor.min():.2f}, {X_train_tensor.max():.2f}]")

# ============================
# 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
# ============================
print("\n" + "="*50)
print("3. æ•°æ®åŠ è½½å™¨")
print("="*50)

# åˆ›å»ºæ•°æ®é›†
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
test_dataset = TensorDataset(X_test_tensor, y_test_tensor)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
print(f"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")

# ============================
# 4. å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹
# ============================
print("\n" + "="*50)
print("4. ç¥ç»ç½‘ç»œæ¨¡å‹")
print("="*50)

class SimpleClassifier(nn.Module):
    """ç®€å•çš„äºŒåˆ†ç±»ç¥ç»ç½‘ç»œ"""
    
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleClassifier, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, output_size)
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        # å‰å‘ä¼ æ’­
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

# åˆ›å»ºæ¨¡å‹
model = SimpleClassifier(input_size=2, hidden_size=64, output_size=2)
model = model.to(device)  # ç§»åŠ¨åˆ°è®¾å¤‡

print(f"æ¨¡å‹ç»“æ„:")
print(model)

# è®¡ç®—å‚æ•°æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"æ€»å‚æ•°æ•°: {total_params}")
print(f"å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params}")

# ============================
# 5. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
# ============================
print("\n" + "="*50)
print("5. æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨")
print("="*50)

criterion = nn.CrossEntropyLoss()  # äº¤å‰ç†µæŸå¤±å‡½æ•°
optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adamä¼˜åŒ–å™¨

print(f"æŸå¤±å‡½æ•°: {criterion}")
print(f"ä¼˜åŒ–å™¨: {optimizer}")

# ============================
# 6. è®­ç»ƒæ¨¡å‹
# ============================
print("\n" + "="*50)
print("6. è®­ç»ƒæ¨¡å‹")
print("="*50)

def train_model(model, train_loader, criterion, optimizer, num_epochs):
    """è®­ç»ƒæ¨¡å‹"""
    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
    train_losses = []
    train_accuracies = []
    
    for epoch in range(num_epochs):
        running_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = model(data)
            loss = criterion(outputs, target)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ›´æ–°å‚æ•°
            optimizer.step()
            
            # ç»Ÿè®¡
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
        
        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        epoch_loss = running_loss / len(train_loader)
        epoch_acc = 100 * correct / total
        
        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_acc)
        
        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')
    
    return train_losses, train_accuracies

# è®­ç»ƒæ¨¡å‹
num_epochs = 50
train_losses, train_accuracies = train_model(model, train_loader, criterion, optimizer, num_epochs)

# ============================
# 7. è¯„ä¼°æ¨¡å‹
# ============================
print("\n" + "="*50)
print("7. æ¨¡å‹è¯„ä¼°")
print("="*50)

def evaluate_model(model, test_loader, criterion):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    test_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            outputs = model(data)
            test_loss += criterion(outputs, target).item()
            
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    
    test_loss /= len(test_loader)
    accuracy = 100 * correct / total
    
    return test_loss, accuracy

test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)
print(f'æµ‹è¯•æŸå¤±: {test_loss:.4f}')
print(f'æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy:.2f}%')

# ============================
# 8. å¯è§†åŒ–ç»“æœ
# ============================
print("\n" + "="*50)
print("8. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹")
print("="*50)

def plot_training_history(train_losses, train_accuracies):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # æŸå¤±æ›²çº¿
    ax1.plot(train_losses)
    ax1.set_title('è®­ç»ƒæŸå¤±')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.grid(True)
    
    # å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(train_accuracies)
    ax2.set_title('è®­ç»ƒå‡†ç¡®ç‡')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('/Users/xiang/Documents/GitHub/NewStart/NewStart/training_history.png', dpi=300, bbox_inches='tight')
    print("è®­ç»ƒå†å²å›¾å·²ä¿å­˜ä¸º training_history.png")

def plot_decision_boundary(model, X, y):
    """ç»˜åˆ¶å†³ç­–è¾¹ç•Œ"""
    model.eval()
    h = 0.1
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    
    grid_points = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()]).to(device)
    
    with torch.no_grad():
        outputs = model(grid_points)
        _, predictions = torch.max(outputs, 1)
        predictions = predictions.cpu().numpy()
    
    predictions = predictions.reshape(xx.shape)
    
    plt.figure(figsize=(10, 8))
    plt.contourf(xx, yy, predictions, alpha=0.8, cmap=plt.cm.RdYlBu)
    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolors='black')
    plt.colorbar(scatter)
    plt.title('ç¥ç»ç½‘ç»œå†³ç­–è¾¹ç•Œ')
    plt.xlabel('ç‰¹å¾ 1')
    plt.ylabel('ç‰¹å¾ 2')
    plt.savefig('/Users/xiang/Documents/GitHub/NewStart/NewStart/decision_boundary.png', dpi=300, bbox_inches='tight')
    print("å†³ç­–è¾¹ç•Œå›¾å·²ä¿å­˜ä¸º decision_boundary.png")

# ç»˜åˆ¶å›¾è¡¨
try:
    plot_training_history(train_losses, train_accuracies)
    plot_decision_boundary(model, X_test, y_test)
except ImportError:
    print("matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–éƒ¨åˆ†")

# ============================
# 9. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
# ============================
print("\n" + "="*50)
print("9. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
print("="*50)

# ä¿å­˜æ¨¡å‹
model_path = '/Users/xiang/Documents/GitHub/NewStart/NewStart/simple_classifier.pth'
torch.save(model.state_dict(), model_path)
print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

# åŠ è½½æ¨¡å‹
new_model = SimpleClassifier(input_size=2, hidden_size=64, output_size=2)
new_model.load_state_dict(torch.load(model_path))
new_model.eval()
print("æ¨¡å‹åŠ è½½æˆåŠŸ")

# éªŒè¯åŠ è½½çš„æ¨¡å‹
test_loss_new, test_accuracy_new = evaluate_model(new_model, test_loader, criterion)
print(f'åŠ è½½åçš„æ¨¡å‹æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy_new:.2f}%')

# ============================
# 10. å•ä¸ªæ ·æœ¬é¢„æµ‹
# ============================
print("\n" + "="*50)
print("10. å•ä¸ªæ ·æœ¬é¢„æµ‹")
print("="*50)

def predict_single_sample(model, x):
    """é¢„æµ‹å•ä¸ªæ ·æœ¬"""
    model.eval()
    with torch.no_grad():
        x_tensor = torch.FloatTensor(x).unsqueeze(0).to(device)  # æ·»åŠ batchç»´åº¦
        output = model(x_tensor)
        probabilities = F.softmax(output, dim=1)
        _, predicted_class = torch.max(output, 1)
        
        return predicted_class.item(), probabilities.squeeze().cpu().numpy()

# é¢„æµ‹å‡ ä¸ªæ ·æœ¬
test_samples = [[2, 2], [6, 6], [4, 4]]
for sample in test_samples:
    pred_class, probabilities = predict_single_sample(model, sample)
    print(f"æ ·æœ¬ {sample}: é¢„æµ‹ç±»åˆ« = {pred_class}, æ¦‚ç‡ = {probabilities}")

print("\n" + "="*50)
print("PyTorch æ ¸å¿ƒæ¦‚å¿µæ€»ç»“")
print("="*50)
print("""
ğŸ”¥ PyTorch æ ¸å¿ƒæ¦‚å¿µ:

1. **å¼ é‡ (Tensors)**: PyTorchçš„åŸºæœ¬æ•°æ®ç»“æ„ï¼Œç±»ä¼¼NumPyæ•°ç»„ä½†æ”¯æŒGPUåŠ é€Ÿ
2. **è‡ªåŠ¨å¾®åˆ†**: torch.autograd è‡ªåŠ¨è®¡ç®—æ¢¯åº¦
3. **nn.Module**: æ‰€æœ‰ç¥ç»ç½‘ç»œçš„åŸºç±»
4. **DataLoader**: é«˜æ•ˆçš„æ•°æ®æ‰¹å¤„ç†å’ŒåŠ è½½
5. **ä¼˜åŒ–å™¨**: è‡ªåŠ¨æ›´æ–°æ¨¡å‹å‚æ•°
6. **è®¾å¤‡ç®¡ç†**: CPU/GPUä¹‹é—´çš„æ•°æ®ç§»åŠ¨

ğŸš€ è®­ç»ƒæµç¨‹:
1. å®šä¹‰æ¨¡å‹ â†’ 2. å‡†å¤‡æ•°æ® â†’ 3. å‰å‘ä¼ æ’­ â†’ 4. è®¡ç®—æŸå¤± â†’ 5. åå‘ä¼ æ’­ â†’ 6. æ›´æ–°å‚æ•°

ğŸ’¡ å…³é”®æ–¹æ³•:
- model.train(): è®­ç»ƒæ¨¡å¼
- model.eval(): è¯„ä¼°æ¨¡å¼  
- optimizer.zero_grad(): æ¢¯åº¦æ¸…é›¶
- loss.backward(): åå‘ä¼ æ’­
- optimizer.step(): å‚æ•°æ›´æ–°
- torch.no_grad(): ç¦ç”¨æ¢¯åº¦è®¡ç®—
""")
